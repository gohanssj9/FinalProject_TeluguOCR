{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from scipy.misc import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 32,32\n",
    "\n",
    "train_data_dir = '../SmallTelugu/train'\n",
    "validation_data_dir = '../SmallTelugu/test/'\n",
    "nb_train_samples = 68400\n",
    "nb_validation_samples = 20520\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "CLASSES=[str(i) for i in range(1,685)]\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 32, 32, 20)        560       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 16, 16, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 16, 16, 50)        9050      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 768)               1229568   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 684)               525996    \n",
      "=================================================================\n",
      "Total params: 1,810,274\n",
      "Trainable params: 1,810,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "model.add(Conv2D(20, (3, 3), activation='relu',padding = 'same', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(50, (3, 3), activation='relu',padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))              \n",
    "model.add(Conv2D(100, (3, 3), activation='relu',padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(768, activation='relu'))              \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(684, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "filepath=\"model_chars_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68400 images belonging to 684 classes.\n",
      "Found 27360 images belonging to 684 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255   \n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    classes=CLASSES,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory=validation_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    classes=CLASSES,\n",
    "    batch_size=batch_size\n",
    ")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 5.7591 - acc: 0.0271Epoch 00001: val_acc improved from -inf to 0.14854, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 996s 466ms/step - loss: 5.7560 - acc: 0.0273 - val_loss: 3.9712 - val_acc: 0.1485\n",
      "Epoch 2/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 3.1581 - acc: 0.2357Epoch 00002: val_acc improved from 0.14854 to 0.47580, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 434s 203ms/step - loss: 3.1562 - acc: 0.2360 - val_loss: 1.9973 - val_acc: 0.4758\n",
      "Epoch 3/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 1.8547 - acc: 0.4757Epoch 00003: val_acc improved from 0.47580 to 0.65545, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 215s 101ms/step - loss: 1.8540 - acc: 0.4759 - val_loss: 1.2235 - val_acc: 0.6554\n",
      "Epoch 4/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 1.2222 - acc: 0.6326Epoch 00004: val_acc improved from 0.65545 to 0.75409, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 224s 105ms/step - loss: 1.2215 - acc: 0.6328 - val_loss: 0.8387 - val_acc: 0.7541\n",
      "Epoch 5/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.8759 - acc: 0.7267Epoch 00005: val_acc improved from 0.75409 to 0.81385, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 239s 112ms/step - loss: 0.8763 - acc: 0.7268 - val_loss: 0.6300 - val_acc: 0.8139\n",
      "Epoch 6/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.6582 - acc: 0.7919Epoch 00006: val_acc improved from 0.81385 to 0.85256, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 234s 109ms/step - loss: 0.6580 - acc: 0.7919 - val_loss: 0.4919 - val_acc: 0.8526\n",
      "Epoch 7/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.5131 - acc: 0.8345Epoch 00007: val_acc improved from 0.85256 to 0.86817, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 221s 103ms/step - loss: 0.5134 - acc: 0.8345 - val_loss: 0.4302 - val_acc: 0.8682\n",
      "Epoch 8/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.4120 - acc: 0.8655Epoch 00008: val_acc improved from 0.86817 to 0.88366, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 221s 103ms/step - loss: 0.4119 - acc: 0.8654 - val_loss: 0.3642 - val_acc: 0.8837\n",
      "Epoch 9/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.3344 - acc: 0.8903Epoch 00009: val_acc improved from 0.88366 to 0.89492, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 221s 103ms/step - loss: 0.3341 - acc: 0.8904 - val_loss: 0.3293 - val_acc: 0.8949\n",
      "Epoch 10/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.2820 - acc: 0.9080Epoch 00010: val_acc improved from 0.89492 to 0.90610, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 222s 104ms/step - loss: 0.2822 - acc: 0.9078 - val_loss: 0.2899 - val_acc: 0.9061\n",
      "Epoch 11/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.2384 - acc: 0.9203Epoch 00011: val_acc improved from 0.90610 to 0.91239, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 222s 104ms/step - loss: 0.2385 - acc: 0.9203 - val_loss: 0.2832 - val_acc: 0.9124\n",
      "Epoch 12/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.2054 - acc: 0.9319Epoch 00012: val_acc improved from 0.91239 to 0.91915, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 222s 104ms/step - loss: 0.2052 - acc: 0.9319 - val_loss: 0.2556 - val_acc: 0.9192\n",
      "Epoch 13/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9412Epoch 00013: val_acc improved from 0.91915 to 0.92292, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 221s 104ms/step - loss: 0.1757 - acc: 0.9413 - val_loss: 0.2410 - val_acc: 0.9229\n",
      "Epoch 14/15\n",
      "2136/2137 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9482Epoch 00014: val_acc improved from 0.92292 to 0.92533, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 252s 118ms/step - loss: 0.1577 - acc: 0.9482 - val_loss: 0.2336 - val_acc: 0.9253\n",
      "Epoch 15/15\n",
      "2136/2137 [============================>.] - ETA: 1s - loss: 0.1391 - acc: 0.9528Epoch 00015: val_acc improved from 0.92533 to 0.92829, saving model to model_chars_weights.hdf5\n",
      "2138/2137 [==============================] - 2402s 1s/step - loss: 0.1390 - acc: 0.9528 - val_loss: 0.2266 - val_acc: 0.9283\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    shuffle = 'batch',\n",
    "    callbacks = [checkpoint])\n",
    "\n",
    "model.save('FinalNet_save_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
